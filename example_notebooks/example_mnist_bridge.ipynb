{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def git_repo_root():\n",
    "    # Run the 'git rev-parse --show-toplevel' command to get the root directory of the Git repository\n",
    "    try:\n",
    "        root = subprocess.check_output(['git', 'rev-parse', '--show-toplevel'], universal_newlines=True).strip()\n",
    "        return root\n",
    "    except subprocess.CalledProcessError:\n",
    "        # Handle the case where the current directory is not inside a Git repository\n",
    "        return None\n",
    "\n",
    "# Get the root directory of the Git repository\n",
    "git_root = git_repo_root()\n",
    "\n",
    "if git_root:\n",
    "    # Change the working directory to the root of the Git repository\n",
    "    os.chdir(git_root)\n",
    "    print(f\"Changed working directory to: {git_root}\")\n",
    "else:\n",
    "    print(\"Not inside a Git repository.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusion import VPSDE\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from diffusion import VPSDE\n",
    "from torch.utils.data import DataLoader\n",
    "from training import train_score_network_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = transforms.Compose([transforms.ToTensor(), transforms.Pad(2)])\n",
    "data_x = torchvision.datasets.MNIST(f'./data/', transform=tfm, download = True)\n",
    "data_x = torchvision.datasets.EMNIST( f'./data/', 'letters', transform=tfm, download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a custom transform to correct the orientation of EMNIST images\n",
    "class CorrectEMNISTOrientation(object):\n",
    "    def __call__(self, img):\n",
    "        # Rotate 90 degrees counter-clockwise\n",
    "        img = transforms.functional.rotate(img, -90)\n",
    "        # Flip horizontally\n",
    "        img = transforms.functional.hflip(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "# Transform: Convert images to tensor and pad\n",
    "tfm = transforms.Compose([transforms.ToTensor(), transforms.Pad(2)])\n",
    "\n",
    "emnist_tfm = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Pad(2),\n",
    "    CorrectEMNISTOrientation()\n",
    "])\n",
    "# Load MNIST dataset\n",
    "mnist_data = torchvision.datasets.MNIST('./data/', transform=tfm, download=True)\n",
    "mnist_loader = torch.utils.data.DataLoader(mnist_data, batch_size=5, shuffle=True)\n",
    "\n",
    "# Load EMNIST dataset\n",
    "\n",
    "emnist_data = torchvision.datasets.EMNIST('./data/', 'letters', transform=emnist_tfm, download=True)\n",
    "emnist_loader = torch.utils.data.DataLoader(emnist_data, batch_size=5, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from diffusion import BridgeDiffusionVPSDE\n",
    "\n",
    "def apply_diffusion(x, y, sde, time_steps):\n",
    "    \"\"\"\n",
    "    Applies diffusion to a batch of images x for a given set of time steps.\n",
    "    x: input images \n",
    "    y: target images \n",
    "    sde: instance of your SDE class\n",
    "    time_steps: array of time steps at which to visualize the diffusion\n",
    "    \"\"\"\n",
    "    diffused_images = []\n",
    "    for t in time_steps:\n",
    "        mu, std = sde.marginal(x, torch.tensor([t]), y)\n",
    "        noisy_x = mu + std * torch.randn_like(x)\n",
    "        diffused_images.append(noisy_x)\n",
    "    return diffused_images\n",
    "\n",
    "def show_diffused_images(diffused_images, time_steps):\n",
    "    \"\"\"\n",
    "    Visualizes diffused images at different time steps.\n",
    "    diffused_images: list of tensors containing diffused images at each time step\n",
    "    time_steps: corresponding time steps\n",
    "    \"\"\"\n",
    "    num_steps = len(time_steps)\n",
    "    fig, axes = plt.subplots(nrows=num_steps, ncols=5, figsize=(15, 3 * num_steps))\n",
    "    for i in range(num_steps):\n",
    "        for j in range(5):\n",
    "            ax = axes[i, j]\n",
    "            ax.imshow(diffused_images[i][j].detach().numpy().squeeze(), cmap='gray')\n",
    "            ax.set_title(f\"Time: {time_steps[i]}\")\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def sample():\n",
    "    x, y = next(iter(emnist_loader))\n",
    "    return x\n",
    "\n",
    "mnist_images, mnist_labels = next(iter(mnist_loader))\n",
    "emnist_images, emnist_labels = next(iter(emnist_loader))\n",
    "\n",
    "sde_instance = BridgeDiffusionVPSDE(sample, bmin= .1, bmax=2)  \n",
    "time_steps = [0, 0.25, 0.5, 0.75, 1.0]  \n",
    "\n",
    "diffused_images = apply_diffusion(mnist_images, emnist_images, sde_instance, time_steps)\n",
    "show_diffused_images(diffused_images, time_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from denoising_diffusion_pytorch import Unet\n",
    "# Load MNIST dataset\n",
    "device='cpu'\n",
    "batch_size=5\n",
    "\n",
    "\n",
    "mnist_data = torchvision.datasets.MNIST('./data/', transform=tfm, download=True)\n",
    "mnist_loader = DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Load EMNIST dataset\n",
    "emnist_data = torchvision.datasets.EMNIST('./data/', 'letters', transform=emnist_tfm, download=True)\n",
    "emnist_loader = DataLoader(emnist_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def data_y(n):\n",
    "    # Create a new DataLoader with batch_size = n\n",
    "    temp_loader = DataLoader(emnist_data, batch_size=n, shuffle=True)\n",
    "\n",
    "    # Fetch one batch of data\n",
    "    for data, labels in temp_loader:\n",
    "        return data # This returns n samples\n",
    "\n",
    "model = Unet(out_dim=1, channels = 2, dim = 32).to(device)\n",
    "sde = BridgeDiffusionVPSDE(data_y,  bmin=0.2, bmax=0.2, device = device)\n",
    "\n",
    "n_examples = 5  # number of examples to generate\n",
    "with torch.no_grad():\n",
    "    samples = sde.backward_diffusion(\n",
    "    model, data_shape=(n_examples, 1, 32, 32)).detach().cpu().numpy()\n",
    "\n",
    "    _, axes = plt.subplots(1, n_examples)\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(samples[i].squeeze())\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bridge_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}